## Introduction
Hello! It's Clarence, the creator of this repository. This repo contains codes used for my assignments and examination when I took the module EE2211 in AY23/24 Semester 1 under Prof Wang Xinchao and Dr Helen Zhou.

Introduction to Machine Learning was a simple crash course into machine learning concepts, and a good ease into the ideas that are common in machine learning. However, it really was just a toe-dip into the lake that was ML, 
as I found that many important topics were not covered very in-depth (Neural Networks), and it felt more like a math module with sprinkles of programming fitted in.

Nevertheless, here is my code for reference if you are taking this module. Please do take note of NUS' Plagiarism Policy and exercise discretion when viewing past assignments' code. 

## More on Master Function folder
The Master Function folder contains code that I wrote to help me during the EE2211 midterms as well as the finals. Documentation has been written for each major function, so do take a look there for some explanations. 
The entry to the main function is found under `my version of code.py` (horrible naming sense, i know... i was stressed). Run the program in your IDE of choice (I used Jupyter Spyder) and from there you can access the different programs:
1. Linear algebra matrix related functions. [Matrix X and Vector Y]
2. Checking invertibility, presence of left and right inverses for a matrix X [alone]. Also calculates the number of parameters a polynomial model has to learn.
3. Regression: linear and polynomial.
4. Gradient descent. 
5. Performance metrics (Gini Coefficient, Entropy, Misclassification rate for single node)
6. MSE calculation of regression tree.
7. Confusion matrix related functions.
8. K-Means cluster calculations. (You might be better off hand-calculating these, as the exams are unlikely to test for high-iterations.)
9. Input anything else to exit.

A lot of the programs are very input-heavy, requiring you to make multiple inputs to key in data (which is heavily exacerbated when you have a big matrix!).

This is (unfortunately) a feature, as I did not have the time (nor bothered to) optimize the program for 2 exams. 

You can try to optimize it, but I'd just learn to get used to it. It's honestly not worth it IMO ðŸ˜†

If you do use the code for yourself, do let me know if it was helpful! I'd be glad to hear from you!
